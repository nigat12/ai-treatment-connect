{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20216fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from collections import Counter\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import math\n",
    "\n",
    "# CONFIG\n",
    "CSV_FILENAME = 'drug_data.csv'\n",
    "TEXT_COLUMNS_FOR_EMBEDDING = ['Cancer Type']\n",
    "OUTCOME_COLUMNS = ['Treatment_OS', 'Control_OS', 'OS_Improvement (%)', 'Treatment_PFS', 'Control_PFS', 'PFS_Improvement (%)']\n",
    "RELEVANCE_SCORE_THRESHOLD = 0.5\n",
    "HF_MODEL_NAME = 'dmis-lab/biobert-v1.1'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "print(\"\\nLoading Hugging Face model...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_NAME)\n",
    "    model = AutoModel.from_pretrained(HF_MODEL_NAME).to(DEVICE)\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c05569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z0-9\\s-]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    return ''\n",
    "\n",
    "def parse_time_to_months(time_str):\n",
    "    if isinstance(time_str, (int, float)):\n",
    "        return float(time_str)\n",
    "    if not isinstance(time_str, str):\n",
    "        return None\n",
    "    time_str = time_str.strip().lower()\n",
    "    if time_str in ['n/a', 'not applicable', 'not reported', 'not reached', 'nr']:\n",
    "        return None\n",
    "    match = re.match(r'(\\d+(\\.\\d+)?)\\s*(month|year)s?', time_str)\n",
    "    if match:\n",
    "        value = float(match.group(1))\n",
    "        unit = match.group(3)\n",
    "        return value * 12 if unit == 'year' else value\n",
    "    return None\n",
    "\n",
    "def parse_improvement_percentage(perc_str):\n",
    "    if isinstance(perc_str, (int, float)):\n",
    "        return float(perc_str)\n",
    "    if not isinstance(perc_str, str):\n",
    "        return None\n",
    "    perc_str = perc_str.strip().lower()\n",
    "    if perc_str in ['n/a', 'not statistically significant', 'not reported']:\n",
    "        return None\n",
    "    match = re.match(r'(\\d+(\\.\\d+)?)\\s*%', perc_str)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "def get_mean_pooling_embedding(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden = outputs.last_hidden_state\n",
    "    mask = inputs['attention_mask'].unsqueeze(-1).expand(last_hidden.size()).float()\n",
    "    sum_embeddings = torch.sum(last_hidden * mask, dim=1)\n",
    "    sum_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "    mean_pooled = (sum_embeddings / sum_mask).cpu().numpy()\n",
    "    return mean_pooled[0]\n",
    "\n",
    "def embed_texts(text_list, tokenizer, model, device='cpu'):\n",
    "    return np.array([get_mean_pooling_embedding(text, tokenizer, model, device) for text in text_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7870d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "print(\"\\nLoading and cleaning data...\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "df = pd.read_csv(CSV_FILENAME)\n",
    "\n",
    "df['combined_text_cleaned_for_embedding'] = df[TEXT_COLUMNS_FOR_EMBEDDING].fillna('').agg(' '.join, axis=1).map(clean_text)\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"\\nGenerating embeddings...\")\n",
    "drug_embeddings = embed_texts(df['combined_text_cleaned_for_embedding'].tolist(), tokenizer, model, device)\n",
    "print(\"Embeddings generated.\")\n",
    "\n",
    "# User query + similarity\n",
    "def get_top_matches(user_query, top_k=5):\n",
    "    user_cleaned = clean_text(user_query)\n",
    "    user_embedding = get_mean_pooling_embedding(user_cleaned, tokenizer, model, device)\n",
    "    sims = cosine_similarity([user_embedding], drug_embeddings)[0]\n",
    "    df['semantic_similarity'] = sims\n",
    "    return df.sort_values(by='semantic_similarity', ascending=False).head(top_k)\n",
    "\n",
    "# Example interactive search\n",
    "def on_query_submit(query):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"\\nTop matches for: \\\"{query}\\\"\")\n",
    "    results = get_top_matches(query)\n",
    "    display(results[[*TEXT_COLUMNS_FOR_EMBEDDING, 'semantic_similarity', 'Drug Name',  *OUTCOME_COLUMNS]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc64e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_box = widgets.Text(description='Search:')\n",
    "button = widgets.Button(description=\"Search\")\n",
    "\n",
    "def on_button_click(b):\n",
    "    on_query_submit(search_box.value)\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "display(widgets.HBox([search_box, button]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
